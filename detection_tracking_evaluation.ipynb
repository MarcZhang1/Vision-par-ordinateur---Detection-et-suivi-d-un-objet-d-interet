{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "import cv2\n",
    "import cvzone\n",
    "import math\n",
    "from sort import *\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction de détection et tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_track(FILE_PATH_IMG, FILE_PATH_RESULTS,file_name = \"/results.txt\" , sort = False, show = False, className=\"person\", max_age=20, min_hits=1, iou_threshold=0.3, conf_yolo=0.5):\n",
    "\n",
    "    model = YOLO(\"yolov8l.pt\")\n",
    "    classNames = model.names\n",
    "    tracker = Sort(max_age=max_age, min_hits=min_hits,iou_threshold=iou_threshold)\n",
    "    \n",
    "    folder_files_img = os.listdir(FILE_PATH_IMG)\n",
    "    if sort:\n",
    "        folder_files_img = sorted(folder_files_img, key=lambda x: int(x[5:-4]))\n",
    "\n",
    "    if not os.path.exists(FILE_PATH_RESULTS):\n",
    "        os.makedirs(FILE_PATH_RESULTS)\n",
    "    f = open(FILE_PATH_RESULTS+file_name, \"w\")\n",
    "\n",
    "    for frame, picture in enumerate(tqdm(folder_files_img), 1):\n",
    "        img = cv2.imread(f\"{FILE_PATH_IMG}/{picture}\")\n",
    "        result = model(img, verbose=False)\n",
    "        detections = np.empty((0,5))\n",
    "        \n",
    "        # conf_list = []\n",
    "        \n",
    "        for r in result:\n",
    "            boxes = r.boxes\n",
    "            for box in boxes:\n",
    "                #Score de confiance\n",
    "                conf = math.ceil(box.conf[0]*100)/100\n",
    "                \n",
    "                #For bounding box\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                # bbox = x1, y1, x2, y2\n",
    "                # w, h = x2-x1, y2-y1\n",
    "                \n",
    "                #For confidence box\n",
    "                cls = int(box.cls[0])\n",
    "                curr_class = classNames[cls]\n",
    "                \n",
    "                # conf_list.append(conf)\n",
    "                \n",
    "                if curr_class == className and conf > conf_yolo:\n",
    "                    if show:\n",
    "                        cvzone.putTextRect(img, f\"{model.names[cls]} {conf}\", (x2, y2), scale=1, thickness=1, colorR=(0,0,255))\n",
    "                    currentArray = np.array([[x1, y1, x2, y2, conf]])\n",
    "                    detections = np.vstack((detections, currentArray))\n",
    "        \n",
    "        results_tracker = tracker.update(detections)\n",
    "        \n",
    "        for i, res in enumerate(results_tracker):\n",
    "            x1, y1, x2, y2, id = res\n",
    "            x1, y1, x2, y2, id = int(x1), int(y1), int(x2), int(y2), int(id)\n",
    "            w, h = x2-x1, y2-y1\n",
    "            \n",
    "            if show:\n",
    "                cvzone.putTextRect(img, f\"ID: {id}\", (x1, y1), scale=1, thickness=1, colorR=(0,0,255))\n",
    "                cvzone.cornerRect(img, (x1, y1, w, h), l=9, rt=1, colorR=(255,0,255))\n",
    "            \n",
    "            f.write(f\"{frame},{id},{x1},{y1},{w},{h},1,-1,-1,-1\\n\")\n",
    "        \n",
    "        if show:\n",
    "            cv2.imshow(\"Image\", img)\n",
    "            cv2.waitKey(1)                          \n",
    "        \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 429/429 [03:55<00:00,  1.83it/s]\n",
      "100%|██████████| 2782/2782 [23:22<00:00,  1.98it/s]\n",
      "100%|██████████| 2405/2405 [22:51<00:00,  1.75it/s]\n",
      "100%|██████████| 3315/3315 [31:07<00:00,  1.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# Fais la détection et le tracking pour le dataset MOT20\n",
    "\n",
    "train_datasets = os.listdir(\"datasets/MOT20/train\")\n",
    "\n",
    "for dataset in train_datasets:\n",
    "    PATH_IMG = f\"datasets/MOT20/train/{dataset}/img1\"\n",
    "    PATH_RESULTS = f\"datasets/MOT20/train/{dataset}/results\"\n",
    "    detect_and_track(PATH_IMG, PATH_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_age:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 429/429 [03:38<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_age:  30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 429/429 [03:39<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iou_threshold:  0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 429/429 [03:33<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iou_threshold:  0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 429/429 [03:29<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iou_threshold:  0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 429/429 [03:30<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iou_threshold:  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 429/429 [03:33<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf_yolo:  0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 429/429 [03:28<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf_yolo:  0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 429/429 [03:38<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf_yolo:  0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 429/429 [03:26<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf_yolo:  0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 429/429 [03:25<00:00,  2.09it/s]\n"
     ]
    }
   ],
   "source": [
    "#max_age=20, min_hits=1, iou_threshold=0.3, conf_yolo=0.5\n",
    "max_age_list = [5, 10, 15, 25, 30, 35]\n",
    "min_hits_list = [ 2, 3, 4]\n",
    "iou_threshold_list = [0.1, 0.2, 0.4, 0.5]\n",
    "conf_yolo_list = [0.1, 0.2, 0.3, 0.4, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "for max_age in max_age_list:\n",
    "    print(\"max_age: \", max_age)\n",
    "    PATH_IMG = \"datasets/MOT20/train/MOT20-01/img1\"\n",
    "    PATH_RESULTS = f\"datasets/MOT20/train/MOT20-01/results/results_max_age\"\n",
    "    detect_and_track(PATH_IMG, PATH_RESULTS, max_age=max_age, file_name=f\"/results_max_age_{max_age}.txt\")\n",
    "    \n",
    "for min_hits in min_hits_list:\n",
    "    print(\"min_hits: \", min_hits)\n",
    "    PATH_IMG = \"datasets/MOT20/train/MOT20-01/img1\"\n",
    "    PATH_RESULTS = f\"datasets/MOT20/train/MOT20-01/results/results_min_hits\"\n",
    "    detect_and_track(PATH_IMG, PATH_RESULTS, min_hits=min_hits, file_name=f\"/results_min_hits_{min_hits}.txt\")\n",
    "    \n",
    "for iou_threshold in iou_threshold_list:\n",
    "    print(\"iou_threshold: \", iou_threshold)\n",
    "    PATH_IMG = \"datasets/MOT20/train/MOT20-01/img1\"\n",
    "    PATH_RESULTS = f\"datasets/MOT20/train/MOT20-01/results/results_iou_threshold\"\n",
    "    detect_and_track(PATH_IMG, PATH_RESULTS, iou_threshold=iou_threshold, file_name=f\"/results_iou_threshold_{iou_threshold}.txt\")\n",
    "    \n",
    "for conf_yolo in conf_yolo_list:\n",
    "    print(\"conf_yolo: \", conf_yolo)\n",
    "    PATH_IMG = \"datasets/MOT20/train/MOT20-01/img1\"\n",
    "    PATH_RESULTS = f\"datasets/MOT20/train/MOT20-01/results/results_conf_yolo\"\n",
    "    detect_and_track(PATH_IMG, PATH_RESULTS, conf_yolo=conf_yolo, file_name=f\"/results_conf_yolo_{conf_yolo}.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation du résultat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation avec les valeurs par défaut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval Config:\n",
      "USE_PARALLEL         : False                         \n",
      "NUM_PARALLEL_CORES   : 1                             \n",
      "BREAK_ON_ERROR       : True                          \n",
      "RETURN_ON_ERROR      : False                         \n",
      "LOG_ON_ERROR         : c:\\Users\\marc1\\Desktop\\Cours polytechnique Montréal\\Hiver 2024\\INF6804 - Vision par ordinateur\\TP3V3\\TrackEval\\error_log.txt\n",
      "PRINT_RESULTS        : True                          \n",
      "PRINT_ONLY_COMBINED  : False                         \n",
      "PRINT_CONFIG         : True                          \n",
      "TIME_PROGRESS        : True                          \n",
      "DISPLAY_LESS_PROGRESS : False                         \n",
      "OUTPUT_SUMMARY       : True                          \n",
      "OUTPUT_EMPTY_CLASSES : True                          \n",
      "OUTPUT_DETAILED      : True                          \n",
      "PLOT_CURVES          : True                          \n",
      "\n",
      "MotChallenge2DBox Config:\n",
      "PRINT_CONFIG         : True                          \n",
      "GT_FOLDER            : TrackEval/data/gt/mot_challenge/\n",
      "TRACKERS_FOLDER      : TrackEval/data/trackers/mot_challenge/\n",
      "OUTPUT_FOLDER        : None                          \n",
      "TRACKERS_TO_EVAL     : ['YOLOSORT']                  \n",
      "CLASSES_TO_EVAL      : ['pedestrian']                \n",
      "BENCHMARK            : MOT20                         \n",
      "SPLIT_TO_EVAL        : train                         \n",
      "INPUT_AS_ZIP         : False                         \n",
      "DO_PREPROC           : True                          \n",
      "TRACKER_SUB_FOLDER   : data                          \n",
      "OUTPUT_SUB_FOLDER    :                               \n",
      "TRACKER_DISPLAY_NAMES : None                          \n",
      "SEQMAP_FOLDER        : None                          \n",
      "SEQMAP_FILE          : None                          \n",
      "SEQ_INFO             : None                          \n",
      "GT_LOC_FORMAT        : {gt_folder}/{seq}/gt/gt.txt   \n",
      "SKIP_SPLIT_FOL       : False                         \n",
      "\n",
      "Evaluating 1 tracker(s) on 4 sequence(s) for 1 class(es) on MotChallenge2DBox dataset using the following metrics: HOTA, Count\n",
      "\n",
      "\n",
      "Evaluating YOLOSORT\n",
      "\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20-01)                 0.1661 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1643 sec\n",
      "    HOTA.eval_sequence()                                                   0.1494 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "1 eval_sequence(MOT20-01, YOLOSORT)                                      0.4823 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20-02)                 1.4082 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.8874 sec\n",
      "    HOTA.eval_sequence()                                                   1.0478 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "2 eval_sequence(MOT20-02, YOLOSORT)                                      3.3613 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20-03)                 1.8087 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.6121 sec\n",
      "    HOTA.eval_sequence()                                                   0.7599 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "3 eval_sequence(MOT20-03, YOLOSORT)                                      3.1970 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20-05)                 4.0770 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.6879 sec\n",
      "    HOTA.eval_sequence()                                                   0.6529 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "4 eval_sequence(MOT20-05, YOLOSORT)                                      5.4391 sec\n",
      "\n",
      "All sequences for YOLOSORT finished in 12.48 seconds\n",
      "\n",
      "HOTA: YOLOSORT-pedestrian          HOTA      DetA      AssA      DetRe     DetPr     AssRe     AssPr     LocA      OWTA      HOTA(0)   LocA(0)   HOTALocA(0)\n",
      "MOT20-01                           31.956    19.061    53.738    19.303    83.508    55.609    84.785    84.229    32.181    37.973    81.832    31.074    \n",
      "MOT20-02                           24.007    17.15     33.721    17.397    83.234    34.982    84.948    84.815    24.197    28.349    82.365    23.35     \n",
      "MOT20-03                           4.7259    1.7891    12.543    1.7915    80.184    12.684    84.366    81.842    4.7295    5.8064    79.008    4.5875    \n",
      "MOT20-05                           1.6146    0.36368   7.2248    0.36375   85.371    7.2757    89.408    85.27     1.6148    1.8404    83.562    1.5378    \n",
      "COMBINED                           10.269    3.4036    31.103    3.4132    82.929    32.218    85.338    84.349    10.286    12.095    81.878    9.9034    \n",
      "\n",
      "Count: YOLOSORT-pedestrian         Dets      GT_Dets   IDs       GT_IDs    \n",
      "MOT20-01                           4593      19870     68        74        \n",
      "MOT20-02                           32344     154742    373       270       \n",
      "MOT20-03                           7008      313658    263       702       \n",
      "MOT20-05                           2754      646344    189       1169      \n",
      "COMBINED                           46699     1134614   893       2215      \n",
      "\n",
      "Timing analysis:\n",
      "MotChallenge2DBox.get_raw_seq_data                                     7.4600 sec\n",
      "MotChallenge2DBox.get_preprocessed_seq_data                            2.3517 sec\n",
      "HOTA.eval_sequence                                                     2.6100 sec\n",
      "Count.eval_sequence                                                    0.0000 sec\n",
      "eval_sequence                                                          12.4798 sec\n",
      "Evaluator.evaluate                                                     13.6208 sec\n"
     ]
    }
   ],
   "source": [
    "!python TrackEval/scripts/run_mot_challenge.py --NUM_PARALLEL_CORES 1 --BENCHMARK MOT20 --SPLIT_TO_EVAL train --TRACKERS_TO_EVAL YOLOSORT --METRICS HOTA --GT_FOLDER TrackEval/data/gt/mot_challenge/ --TRACKERS_FOLDER TrackEval/data/trackers/mot_challenge/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recherche d'hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval Config:\n",
      "USE_PARALLEL         : False                         \n",
      "NUM_PARALLEL_CORES   : 1                             \n",
      "BREAK_ON_ERROR       : True                          \n",
      "RETURN_ON_ERROR      : False                         \n",
      "LOG_ON_ERROR         : c:\\Users\\marc1\\Desktop\\Cours polytechnique Montréal\\Hiver 2024\\INF6804 - Vision par ordinateur\\TP3V3\\TrackEval\\error_log.txt\n",
      "PRINT_RESULTS        : True                          \n",
      "PRINT_ONLY_COMBINED  : False                         \n",
      "PRINT_CONFIG         : True                          \n",
      "TIME_PROGRESS        : True                          \n",
      "DISPLAY_LESS_PROGRESS : False                         \n",
      "OUTPUT_SUMMARY       : True                          \n",
      "OUTPUT_EMPTY_CLASSES : True                          \n",
      "OUTPUT_DETAILED      : True                          \n",
      "PLOT_CURVES          : True                          \n",
      "\n",
      "MotChallenge2DBox Config:\n",
      "PRINT_CONFIG         : True                          \n",
      "GT_FOLDER            : TrackEval/data/gt/mot_challenge/\n",
      "TRACKERS_FOLDER      : TrackEval/data/trackers/mot_challenge/\n",
      "OUTPUT_FOLDER        : None                          \n",
      "TRACKERS_TO_EVAL     : ['YOLOSORT']                  \n",
      "CLASSES_TO_EVAL      : ['pedestrian']                \n",
      "BENCHMARK            : MOT20                         \n",
      "SPLIT_TO_EVAL        : train                         \n",
      "INPUT_AS_ZIP         : False                         \n",
      "DO_PREPROC           : True                          \n",
      "TRACKER_SUB_FOLDER   : data                          \n",
      "OUTPUT_SUB_FOLDER    :                               \n",
      "TRACKER_DISPLAY_NAMES : None                          \n",
      "SEQMAP_FOLDER        : None                          \n",
      "SEQMAP_FILE          : None                          \n",
      "SEQ_INFO             : None                          \n",
      "GT_LOC_FORMAT        : {gt_folder}/{seq}/gt/gt.txt   \n",
      "SKIP_SPLIT_FOL       : False                         \n",
      "\n",
      "Evaluating 1 tracker(s) on 29 sequence(s) for 1 class(es) on MotChallenge2DBox dataset using the following metrics: HOTA, Count\n",
      "\n",
      "\n",
      "Evaluating YOLOSORT\n",
      "\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20-01)                 0.1740 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1099 sec\n",
      "    HOTA.eval_sequence()                                                   0.1565 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "1 eval_sequence(MOT20-01, YOLOSORT)                                      0.4432 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20-02)                 1.3752 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.7893 sec\n",
      "    HOTA.eval_sequence()                                                   1.0466 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "2 eval_sequence(MOT20-02, YOLOSORT)                                      3.2324 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20-03)                 2.5629 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.9018 sec\n",
      "    HOTA.eval_sequence()                                                   1.6351 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "3 eval_sequence(MOT20-03, YOLOSORT)                                      5.1411 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20-05)                 4.4487 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                1.0609 sec\n",
      "    HOTA.eval_sequence()                                                   2.3341 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "4 eval_sequence(MOT20-05, YOLOSORT)                                      7.9198 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20_conf_yolo_0.1)      0.2204 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1394 sec\n",
      "    HOTA.eval_sequence()                                                   0.1591 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "5 eval_sequence(MOT20_conf_yolo_0.1, YOLOSORT)                           0.5221 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20_conf_yolo_0.2)      0.2162 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1224 sec\n",
      "    HOTA.eval_sequence()                                                   0.1499 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "6 eval_sequence(MOT20_conf_yolo_0.2, YOLOSORT)                           0.4916 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20_conf_yolo_0.3)      0.1622 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1087 sec\n",
      "    HOTA.eval_sequence()                                                   0.1487 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "7 eval_sequence(MOT20_conf_yolo_0.3, YOLOSORT)                           0.4225 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20_conf_yolo_0.4)      0.1835 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1178 sec\n",
      "    HOTA.eval_sequence()                                                   0.1400 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "8 eval_sequence(MOT20_conf_yolo_0.4, YOLOSORT)                           0.4438 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20_conf_yolo_0.5)      0.1964 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1220 sec\n",
      "    HOTA.eval_sequence()                                                   0.1421 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "9 eval_sequence(MOT20_conf_yolo_0.5, YOLOSORT)                           0.4633 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20_conf_yolo_0.6)      0.1400 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1046 sec\n",
      "    HOTA.eval_sequence()                                                   0.1317 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "10 eval_sequence(MOT20_conf_yolo_0.6, YOLOSORT)                           0.3787 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20_conf_yolo_0.7)      0.1339 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1102 sec\n",
      "    HOTA.eval_sequence()                                                   0.1542 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "11 eval_sequence(MOT20_conf_yolo_0.7, YOLOSORT)                           0.4004 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20_conf_yolo_0.8)      0.1573 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.0977 sec\n",
      "    HOTA.eval_sequence()                                                   0.1000 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "12 eval_sequence(MOT20_conf_yolo_0.8, YOLOSORT)                           0.3565 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20_conf_yolo_0.9)      0.1522 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.0396 sec\n",
      "    HOTA.eval_sequence()                                                   0.0000 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "13 eval_sequence(MOT20_conf_yolo_0.9, YOLOSORT)                           0.1931 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20_iou_threshold_0.1)  0.1551 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1060 sec\n",
      "    HOTA.eval_sequence()                                                   0.1341 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "14 eval_sequence(MOT20_iou_threshold_0.1, YOLOSORT)                       0.3978 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20_iou_threshold_0.2)  0.1719 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1160 sec\n",
      "    HOTA.eval_sequence()                                                   0.1383 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "15 eval_sequence(MOT20_iou_threshold_0.2, YOLOSORT)                       0.4290 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20_iou_threshold_0.3)  0.1648 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1241 sec\n",
      "    HOTA.eval_sequence()                                                   0.1599 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "16 eval_sequence(MOT20_iou_threshold_0.3, YOLOSORT)                       0.4521 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20_iou_threshold_0.4)  0.1718 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1254 sec\n",
      "    HOTA.eval_sequence()                                                   0.1418 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "17 eval_sequence(MOT20_iou_threshold_0.4, YOLOSORT)                       0.4413 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20_iou_threshold_0.5)  0.1719 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1344 sec\n",
      "    HOTA.eval_sequence()                                                   0.1591 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "18 eval_sequence(MOT20_iou_threshold_0.5, YOLOSORT)                       0.4677 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20_max_age_10)         0.1478 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1038 sec\n",
      "    HOTA.eval_sequence()                                                   0.1373 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "19 eval_sequence(MOT20_max_age_10, YOLOSORT)                              0.3913 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20_max_age_15)         0.1480 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1173 sec\n",
      "    HOTA.eval_sequence()                                                   0.1544 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "20 eval_sequence(MOT20_max_age_15, YOLOSORT)                              0.4220 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20_max_age_20)         0.1785 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1125 sec\n",
      "    HOTA.eval_sequence()                                                   0.1511 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "21 eval_sequence(MOT20_max_age_20, YOLOSORT)                              0.4447 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20_max_age_25)         0.2337 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1117 sec\n",
      "    HOTA.eval_sequence()                                                   0.1684 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "22 eval_sequence(MOT20_max_age_25, YOLOSORT)                              0.5169 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20_max_age_30)         0.1774 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1181 sec\n",
      "    HOTA.eval_sequence()                                                   0.1581 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "23 eval_sequence(MOT20_max_age_30, YOLOSORT)                              0.4562 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20_max_age_35)         0.1662 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1085 sec\n",
      "    HOTA.eval_sequence()                                                   0.1350 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "24 eval_sequence(MOT20_max_age_35, YOLOSORT)                              0.4121 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20_max_age_5)          0.1550 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1022 sec\n",
      "    HOTA.eval_sequence()                                                   0.1377 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "25 eval_sequence(MOT20_max_age_5, YOLOSORT)                               0.3972 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20_min_hits_1)         0.1931 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1243 sec\n",
      "    HOTA.eval_sequence()                                                   0.1420 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "26 eval_sequence(MOT20_min_hits_1, YOLOSORT)                              0.4619 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20_min_hits_2)         0.1697 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1021 sec\n",
      "    HOTA.eval_sequence()                                                   0.1415 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "27 eval_sequence(MOT20_min_hits_2, YOLOSORT)                              0.4159 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20_min_hits_3)         0.1529 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1269 sec\n",
      "    HOTA.eval_sequence()                                                   0.1529 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "28 eval_sequence(MOT20_min_hits_3, YOLOSORT)                              0.4353 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20_min_hits_4)         0.1611 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1051 sec\n",
      "    HOTA.eval_sequence()                                                   0.1338 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "29 eval_sequence(MOT20_min_hits_4, YOLOSORT)                              0.4025 sec\n",
      "\n",
      "All sequences for YOLOSORT finished in 27.35 seconds\n",
      "\n",
      "HOTA: YOLOSORT-pedestrian          HOTA      DetA      AssA      DetRe     DetPr     AssRe     AssPr     LocA      OWTA      HOTA(0)   LocA(0)   HOTALocA(0)\n",
      "MOT20-01                           31.569    24.055    42.105    24.723    76.448    44.966    77.464    80.323    32.075    40.167    75.975    30.517    \n",
      "MOT20-02                           24.857    21.81     28.571    22.362    77.953    30.025    78.622    81.476    25.212    30.978    77.408    23.979    \n",
      "MOT20-03                           18.479    14.97     22.976    15.23     71.881    23.682    76.884    76.699    18.659    25.177    71.286    17.947    \n",
      "MOT20-05                           6.7967    3.7833    12.275    3.7938    81.019    12.456    84.394    82.322    6.8078    8.1815    79.496    6.504     \n",
      "MOT20_conf_yolo_0.1                39.508    30.402    51.669    31.236    79.901    55.722    78.761    82.063    40.116    49.115    78.533    38.571    \n",
      "MOT20_conf_yolo_0.2                39.508    30.402    51.669    31.236    79.901    55.722    78.761    82.063    40.116    49.115    78.533    38.571    \n",
      "MOT20_conf_yolo_0.3                38.263    28.139    52.311    28.78     80.931    55.957    80.51     82.591    38.751    47.002    79.491    37.362    \n",
      "MOT20_conf_yolo_0.4                34.93     23.506    52.139    23.901    82.292    54.064    84.173    83.363    35.26     42.177    80.67     34.024    \n",
      "MOT20_conf_yolo_0.5                31.569    24.055    42.105    24.723    76.448    44.966    77.464    80.323    32.075    40.167    75.975    30.517    \n",
      "MOT20_conf_yolo_0.6                27.593    14.678    52.019    14.806    84.808    53.455    86.193    85.08     27.728    32.279    83.043    26.805    \n",
      "MOT20_conf_yolo_0.7                17.096    8.5312    34.43     8.5697    86.524    34.967    89.804    86.235    17.142    19.36     84.677    16.393    \n",
      "MOT20_conf_yolo_0.8                8.4722    2.8994    24.793    2.9028    88.465    24.97     92.499    87.646    8.4776    9.5315    86.54     8.2486    \n",
      "MOT20_conf_yolo_0.9                0         0         0         0         0         0         0         100       0         0         100       0         \n",
      "MOT20_iou_threshold_0.1            31.903    19.093    53.478    19.336    83.504    55.478    83.443    84.229    32.129    37.898    81.826    31.011    \n",
      "MOT20_iou_threshold_0.2            31.972    19.098    53.685    19.338    83.585    55.581    84.686    84.269    32.195    37.985    81.904    31.112    \n",
      "MOT20_iou_threshold_0.3            31.569    24.055    42.105    24.723    76.448    44.966    77.464    80.323    32.075    40.167    75.975    30.517    \n",
      "MOT20_iou_threshold_0.4            31.97     19.093    53.686    19.329    83.676    55.541    84.906    84.299    32.189    37.963    81.983    31.123    \n",
      "MOT20_iou_threshold_0.5            31.887    19.057    53.512    19.29     83.723    55.372    85.273    84.299    32.103    37.85     82.022    31.045    \n",
      "MOT20_max_age_10                   30.571    19.044    49.23     19.278    83.729    50.84     85.605    84.342    30.78     36.326    82.04     29.802    \n",
      "MOT20_max_age_15                   31.93     19.067    53.631    19.306    83.593    55.5      84.717    84.276    32.152    37.925    81.911    31.065    \n",
      "MOT20_max_age_20                   31.956    19.061    53.738    19.303    83.508    55.609    84.785    84.229    32.181    37.973    81.832    31.074    \n",
      "MOT20_max_age_25                   31.832    19.071    53.304    19.313    83.461    55.896    82.734    84.202    32.056    37.855    81.802    30.966    \n",
      "MOT20_max_age_30                   31.864    19.08     53.386    19.322    83.463    55.984    82.696    84.203    32.089    37.894    81.804    30.999    \n",
      "MOT20_max_age_35                   32.555    19.086    55.688    19.326    83.464    58.378    82.754    84.184    32.782    38.762    81.804    31.709    \n",
      "MOT20_max_age_5                    29.523    18.957    46.151    19.189    83.725    47.389    86.544    84.35     29.726    35.082    82.045    28.783    \n",
      "MOT20_min_hits_1                   31.569    24.055    42.105    24.723    76.448    44.966    77.464    80.323    32.075    40.167    75.975    30.517    \n",
      "MOT20_min_hits_2                   31.205    18.043    54.123    18.252    83.836    55.935    85.23     84.416    31.406    36.952    82.131    30.349    \n",
      "MOT20_min_hits_3                   30.674    17.318    54.482    17.507    84.027    56.251    85.666    84.542    30.86     36.241    82.315    29.832    \n",
      "MOT20_min_hits_4                   30.209    16.767    54.576    16.94     84.253    56.302    85.958    84.661    30.381    35.616    82.528    29.393    \n",
      "COMBINED                           21.219    12.546    36.336    12.708    78.462    38.107    81.715    81.241    21.382    26.106    77.415    20.21     \n",
      "\n",
      "Count: YOLOSORT-pedestrian         Dets      GT_Dets   IDs       GT_IDs    \n",
      "MOT20-01                           6426      19870     129       74        \n",
      "MOT20-02                           44391     154742    665       270       \n",
      "MOT20-03                           66456     313658    1222      702       \n",
      "MOT20-05                           30266     646344    1128      1169      \n",
      "MOT20_conf_yolo_0.1                7768      19870     103       74        \n",
      "MOT20_conf_yolo_0.2                7768      19870     103       74        \n",
      "MOT20_conf_yolo_0.3                7066      19870     91        74        \n",
      "MOT20_conf_yolo_0.4                5771      19870     83        74        \n",
      "MOT20_conf_yolo_0.5                6426      19870     129       74        \n",
      "MOT20_conf_yolo_0.6                3469      19870     43        74        \n",
      "MOT20_conf_yolo_0.7                1968      19870     47        74        \n",
      "MOT20_conf_yolo_0.8                652       19870     17        74        \n",
      "MOT20_conf_yolo_0.9                0         19870     0         74        \n",
      "MOT20_iou_threshold_0.1            4601      19870     65        74        \n",
      "MOT20_iou_threshold_0.2            4597      19870     66        74        \n",
      "MOT20_iou_threshold_0.3            6426      19870     129       74        \n",
      "MOT20_iou_threshold_0.4            4590      19870     70        74        \n",
      "MOT20_iou_threshold_0.5            4578      19870     77        74        \n",
      "MOT20_max_age_10                   4575      19870     79        74        \n",
      "MOT20_max_age_15                   4589      19870     70        74        \n",
      "MOT20_max_age_20                   4593      19870     68        74        \n",
      "MOT20_max_age_25                   4598      19870     64        74        \n",
      "MOT20_max_age_30                   4600      19870     62        74        \n",
      "MOT20_max_age_35                   4601      19870     62        74        \n",
      "MOT20_max_age_5                    4554      19870     94        74        \n",
      "MOT20_min_hits_1                   6426      19870     129       74        \n",
      "MOT20_min_hits_2                   4326      19870     62        74        \n",
      "MOT20_min_hits_3                   4140      19870     54        74        \n",
      "MOT20_min_hits_4                   3995      19870     48        74        \n",
      "COMBINED                           264216    1631364   4959      4065      \n",
      "\n",
      "Timing analysis:\n",
      "MotChallenge2DBox.get_raw_seq_data                                     12.8417 sec\n",
      "MotChallenge2DBox.get_preprocessed_seq_data                            5.6627 sec\n",
      "HOTA.eval_sequence                                                     8.6433 sec\n",
      "Count.eval_sequence                                                    0.0001 sec\n",
      "eval_sequence                                                          27.3522 sec\n",
      "Evaluator.evaluate                                                     28.5076 sec\n"
     ]
    }
   ],
   "source": [
    "!python TrackEval/scripts/run_mot_challenge.py --NUM_PARALLEL_CORES 1 --BENCHMARK MOT20 --SPLIT_TO_EVAL train --TRACKERS_TO_EVAL YOLOSORT --METRICS HOTA --GT_FOLDER TrackEval/data/gt/mot_challenge/ --TRACKERS_FOLDER TrackEval/data/trackers/mot_challenge/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_age_list = [5, 10, 15, 20, 25, 30, 35]\n",
    "HOTA_max_age_list = [29.523, 30.571, 31.93, 31.956, 31.832, 31.864, 32.555]\n",
    "min_hits_list = [1, 2, 3, 4]\n",
    "HOTA_min_hits_list = [31.569, 31.205, 30.674, 21.219]\n",
    "iou_threshold_list = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "HOTA_iou_threshold_list = [31.903, 31.972, 31.569, 31.97, 31.887]\n",
    "conf_yolo_list = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "HOTA_conf_yolo_list =[39.508, 39.508, 38.263, 34.93, 31.569, 27.593, 17.096, 8.4722, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot HOTA en fonction de max_age\n",
    "plt.plot(max_age_list, HOTA_max_age_list)\n",
    "plt.xlabel('max_age')\n",
    "plt.ylabel('HOTA')\n",
    "plt.ylim(0, 100)\n",
    "plt.title('HOTA en fonction de max_age')\n",
    "plt.savefig('HOTA_en_fonction_de_max_age.png')\n",
    "plt.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot HOTA en fonction de min_hits\n",
    "plt.plot(min_hits_list, HOTA_min_hits_list)\n",
    "plt.xlabel('min_hits')\n",
    "plt.ylabel('HOTA')\n",
    "plt.ylim(0, 100)\n",
    "plt.title('HOTA en fonction de min_hits')\n",
    "plt.savefig('HOTA_en_fonction_de_min_hits.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot HOTA en fonction de iou_threshold\n",
    "plt.plot(iou_threshold_list, HOTA_iou_threshold_list)\n",
    "plt.xlabel('iou_threshold')\n",
    "plt.ylabel('HOTA')\n",
    "plt.ylim(0, 100)\n",
    "plt.title('HOTA en fonction de iou_threshold')\n",
    "plt.savefig('HOTA_en_fonction_de_iou_threshold.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot HOTA en fonction de conf_yolo\n",
    "plt.plot(conf_yolo_list, HOTA_conf_yolo_list)\n",
    "plt.xlabel('conf_yolo')\n",
    "plt.ylabel('HOTA')\n",
    "plt.ylim(0, 100)\n",
    "plt.title('HOTA en fonction de conf_yolo')\n",
    "plt.savefig('HOTA_en_fonction_de_conf_yolo.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection et tracking avec les meilleurs hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 429/429 [03:38<00:00,  1.96it/s]\n",
      "100%|██████████| 2782/2782 [22:05<00:00,  2.10it/s]\n",
      "100%|██████████| 2405/2405 [23:16<00:00,  1.72it/s]\n",
      "100%|██████████| 3315/3315 [39:28<00:00,  1.40it/s]\n"
     ]
    }
   ],
   "source": [
    "train_datasets = os.listdir(\"datasets/MOT20/train\")\n",
    "\n",
    "for dataset in train_datasets:\n",
    "    PATH_IMG = f\"datasets/MOT20/train/{dataset}/img1\"\n",
    "    PATH_RESULTS = f\"datasets/MOT20/train/{dataset}/results_best\"\n",
    "    detect_and_track(PATH_IMG, PATH_RESULTS, conf_yolo=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval Config:\n",
      "USE_PARALLEL         : False                         \n",
      "NUM_PARALLEL_CORES   : 1                             \n",
      "BREAK_ON_ERROR       : True                          \n",
      "RETURN_ON_ERROR      : False                         \n",
      "LOG_ON_ERROR         : c:\\Users\\marc1\\Desktop\\Cours polytechnique Montréal\\Hiver 2024\\INF6804 - Vision par ordinateur\\TP3V3\\TrackEval\\error_log.txt\n",
      "PRINT_RESULTS        : True                          \n",
      "PRINT_ONLY_COMBINED  : False                         \n",
      "PRINT_CONFIG         : True                          \n",
      "TIME_PROGRESS        : True                          \n",
      "DISPLAY_LESS_PROGRESS : False                         \n",
      "OUTPUT_SUMMARY       : True                          \n",
      "OUTPUT_EMPTY_CLASSES : True                          \n",
      "OUTPUT_DETAILED      : True                          \n",
      "PLOT_CURVES          : True                          \n",
      "\n",
      "MotChallenge2DBox Config:\n",
      "PRINT_CONFIG         : True                          \n",
      "GT_FOLDER            : TrackEval/data/gt/mot_challenge/\n",
      "TRACKERS_FOLDER      : TrackEval/data/trackers/mot_challenge/\n",
      "OUTPUT_FOLDER        : None                          \n",
      "TRACKERS_TO_EVAL     : ['YOLOSORT']                  \n",
      "CLASSES_TO_EVAL      : ['pedestrian']                \n",
      "BENCHMARK            : MOT20                         \n",
      "SPLIT_TO_EVAL        : train                         \n",
      "INPUT_AS_ZIP         : False                         \n",
      "DO_PREPROC           : True                          \n",
      "TRACKER_SUB_FOLDER   : data                          \n",
      "OUTPUT_SUB_FOLDER    :                               \n",
      "TRACKER_DISPLAY_NAMES : None                          \n",
      "SEQMAP_FOLDER        : None                          \n",
      "SEQMAP_FILE          : None                          \n",
      "SEQ_INFO             : None                          \n",
      "GT_LOC_FORMAT        : {gt_folder}/{seq}/gt/gt.txt   \n",
      "SKIP_SPLIT_FOL       : False                         \n",
      "\n",
      "Evaluating 1 tracker(s) on 4 sequence(s) for 1 class(es) on MotChallenge2DBox dataset using the following metrics: HOTA, Count\n",
      "\n",
      "\n",
      "Evaluating YOLOSORT\n",
      "\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20-01_best)            0.1818 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1128 sec\n",
      "    HOTA.eval_sequence()                                                   0.1395 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "1 eval_sequence(MOT20-01_best, YOLOSORT)                                 0.4370 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20-02_best)            1.3015 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.6982 sec\n",
      "    HOTA.eval_sequence()                                                   1.0988 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "2 eval_sequence(MOT20-02_best, YOLOSORT)                                 3.1164 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20-03_best)            1.8805 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.6643 sec\n",
      "    HOTA.eval_sequence()                                                   1.0593 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "3 eval_sequence(MOT20-03_best, YOLOSORT)                                 3.6260 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(YOLOSORT, MOT20-05_best)            3.8557 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.8829 sec\n",
      "    HOTA.eval_sequence()                                                   1.4270 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "4 eval_sequence(MOT20-05_best, YOLOSORT)                                 6.1990 sec\n",
      "\n",
      "All sequences for YOLOSORT finished in 13.38 seconds\n",
      "\n",
      "HOTA: YOLOSORT-pedestrian          HOTA      DetA      AssA      DetRe     DetPr     AssRe     AssPr     LocA      OWTA      HOTA(0)   LocA(0)   HOTALocA(0)\n",
      "MOT20-01_best                      38.263    28.139    52.311    28.78     80.931    55.957    80.51     82.591    38.751    47.002    79.491    37.362    \n",
      "MOT20-02_best                      29.118    24.636    34.627    25.246    80.671    36.571    81.696    83.301    29.516    35.403    80.155    28.377    \n",
      "MOT20-03_best                      12.375    7.8745    19.521    7.9386    75.588    19.91     80.198    79.178    12.43     16.043    75.117    12.051    \n",
      "MOT20-05_best                      5.9957    3.0953    11.722    3.1016    82.553    11.87     86.317    83.36     6.0034    7.0518    80.925    5.7067    \n",
      "COMBINED                           14.415    7.8485    26.721    7.9086    79.607    28.021    82.885    82.113    14.479    17.596    78.811    13.868    \n",
      "\n",
      "Count: YOLOSORT-pedestrian         Dets      GT_Dets   IDs       GT_IDs    \n",
      "MOT20-01_best                      7066      19870     91        74        \n",
      "MOT20-02_best                      48427     154742    457       270       \n",
      "MOT20-03_best                      32942     313658    674       702       \n",
      "MOT20-05_best                      24284     646344    728       1169      \n",
      "COMBINED                           112719    1134614   1950      2215      \n",
      "\n",
      "Timing analysis:\n",
      "MotChallenge2DBox.get_raw_seq_data                                     7.2195 sec\n",
      "MotChallenge2DBox.get_preprocessed_seq_data                            2.3582 sec\n",
      "HOTA.eval_sequence                                                     3.7247 sec\n",
      "Count.eval_sequence                                                    0.0000 sec\n",
      "eval_sequence                                                          13.3783 sec\n",
      "Evaluator.evaluate                                                     14.7188 sec\n"
     ]
    }
   ],
   "source": [
    "!python TrackEval/scripts/run_mot_challenge.py --NUM_PARALLEL_CORES 1 --BENCHMARK MOT20 --SPLIT_TO_EVAL train --TRACKERS_TO_EVAL YOLOSORT --METRICS HOTA --GT_FOLDER TrackEval/data/gt/mot_challenge/ --TRACKERS_FOLDER TrackEval/data/trackers/mot_challenge/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Détection pour le dataset moodle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_track_moodle(FILE_PATH_IMG, FILE_PATH_RESULTS,file_name = \"/results.txt\" , sort = False, show = False, className=\"person\", max_age=20, min_hits=1, iou_threshold=0.3, conf_yolo=0.5):\n",
    "    \"\"\" Différence avec le premier detect and track est le format du fichier résultat \"\"\"\n",
    "    \n",
    "    model = YOLO(\"yolov8l.pt\")\n",
    "    classNames = model.names\n",
    "    tracker = Sort(max_age=max_age, min_hits=min_hits,iou_threshold=iou_threshold)\n",
    "    \n",
    "    folder_files_img = os.listdir(FILE_PATH_IMG)\n",
    "    if sort:\n",
    "        folder_files_img = sorted(folder_files_img, key=lambda x: int(x[5:-4]))\n",
    "\n",
    "    if not os.path.exists(FILE_PATH_RESULTS):\n",
    "        os.makedirs(FILE_PATH_RESULTS)\n",
    "    f = open(FILE_PATH_RESULTS+file_name, \"w\")\n",
    "\n",
    "    for frame, picture in enumerate(tqdm(folder_files_img), 1):\n",
    "        img = cv2.imread(f\"{FILE_PATH_IMG}/{picture}\")\n",
    "        result = model(img, verbose=False)\n",
    "        detections = np.empty((0,5))\n",
    "        \n",
    "        # conf_list = []\n",
    "        \n",
    "        for r in result:\n",
    "            boxes = r.boxes\n",
    "            for box in boxes:\n",
    "                #Score de confiance\n",
    "                conf = math.ceil(box.conf[0]*100)/100\n",
    "                \n",
    "                #For bounding box\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                # bbox = x1, y1, x2, y2\n",
    "                # w, h = x2-x1, y2-y1\n",
    "                \n",
    "                #For confidence box\n",
    "                cls = int(box.cls[0])\n",
    "                curr_class = classNames[cls]\n",
    "                \n",
    "                # conf_list.append(conf)\n",
    "                \n",
    "                if curr_class == \"cup\" and conf > conf_yolo:\n",
    "                    if show:\n",
    "                        cvzone.putTextRect(img, f\"{model.names[cls]} {conf}\", (x2, y2), scale=1, thickness=1, colorR=(0,0,255))\n",
    "                    currentArray = np.array([[x1, y1, x2, y2, conf]])\n",
    "                    detections = np.vstack((detections, currentArray))\n",
    "        \n",
    "        results_tracker = tracker.update(detections)\n",
    "        \n",
    "        for i, res in enumerate(results_tracker):\n",
    "            x1, y1, x2, y2, id = res\n",
    "            x1, y1, x2, y2, id = int(x1), int(y1), int(x2), int(y2), int(id)\n",
    "            w, h = x2-x1, y2-y1\n",
    "            \n",
    "            if show:\n",
    "                cvzone.putTextRect(img, f\"ID: {id}\", (x1, y1), scale=1, thickness=1, colorR=(0,0,255))\n",
    "                cvzone.cornerRect(img, (x1, y1, w, h), l=9, rt=1, colorR=(255,0,255))\n",
    "            \n",
    "            f.write(f\"{frame},{id},{x1},{y1},{w},{h}\\n\")\n",
    "        \n",
    "        if show:\n",
    "            cv2.imshow(\"Image\", img)\n",
    "            cv2.waitKey(1)                          \n",
    "        \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1385/1385 [11:35<00:00,  1.99it/s]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "detect_and_track_moodle(\"datasets/dataset_moodle/frames\", \"datasets/dataset_moodle/results\",sort=True , show=True, conf_yolo=0.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
